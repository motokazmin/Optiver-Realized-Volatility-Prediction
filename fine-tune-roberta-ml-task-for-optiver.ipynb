{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport itertools\nfrom tokenizers.models import WordLevel\nfrom tokenizers import Tokenizer, models, pre_tokenizers, trainers\nfrom transformers import LineByLineTextDataset\nfrom joblib import Parallel, delayed\n\nfrom transformers import RobertaTokenizerFast\nfrom transformers import LineByLineTextDataset\nfrom transformers import RobertaConfig\nfrom transformers import RobertaForMaskedLM\nfrom transformers import Trainer, TrainingArguments\nfrom transformers import DataCollatorForLanguageModeling\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_train_test():\n    train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n    print(f'Our training set has {train.shape[0]} rows')\n    return train, test\n\ndef calc_wap1(df):\n    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n    return wap\n\ndef log_return(series):\n    return np.log(series).diff()\n\ndef book_preprocessor(file_path, delta):\n    df = pd.read_parquet(file_path)[['time_id', 'seconds_in_bucket', 'bid_price1', 'ask_price1', 'bid_size1', 'ask_size1']]\n    df['wap1'] = calc_wap1(df)\n    df['i'] = ((df['wap1'] - wap1_min)/delta).astype(int)\n    return list(df.groupby(['time_id']).apply(convert_to_str).values)\n    \ndef convert_to_str(g):\n    s = ''.join(str(g.i.values)).replace('\\n', '')\n    return s[1: len(s) - 1] + ' . '\n\ndef preprocessor(list_stock_ids, delta, is_train = True):\n    \n    # Parrallel for loop\n    def for_joblib(stock_id):\n        # Train\n        if is_train:\n            file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n        # Test\n        else:\n            file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n    \n        # Preprocess book and trade data and merge them\n        return book_preprocessor(file_path_book, delta)\n    \n    # Use parallel api to call paralle for loop\n    df = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(stock_id) for stock_id in list_stock_ids)\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"delta = 0.0002\nwap1_min = 0.8830628395080566\nwap1_max = 1.1270768642425537\nvocab_size = int((wap1_max - wap1_min)/delta) + 2\nnum_secs_max = 600","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/optiver-realized-volatility-prediction/'\n\nidx0 = 0\nidx1 = 2\ntrain, test = read_train_test()\ntrain_stock_ids = train['stock_id'].unique()[idx0:idx1]\ntrain_ = preprocessor(train_stock_ids, delta, is_train = True)\nmerged_data = list(itertools.chain(*train_))\n\ntextfile = open(\"train_data.txt\", \"w\")\nfor element in merged_data:\n    textfile.write(element +'\\n')\ntextfile.close()\n\ndel train_\ndel merged_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = RobertaTokenizerFast.from_pretrained('../input/krv-tokenizer')\ndataset = LineByLineTextDataset(\n    tokenizer=tokenizer,\n    file_path=\".//train_data.txt\",\n    block_size=128,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from_pretrained = True\n\nconfig = RobertaConfig(\n    vocab_size=len(tokenizer.get_vocab()),\n    max_position_embeddings=600,\n    num_attention_heads=12,\n    num_hidden_layers=6,\n    type_vocab_size=1,\n)\n\nif from_pretrained:\n    model = RobertaForMaskedLM.from_pretrained('../input/bert-for-optiver')\nelse:\n    model = RobertaForMaskedLM(config=config)\n\nprint(f'Num of model parameters = {model.num_parameters()}')\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./optiver\",\n    overwrite_output_dir=True,\n    num_train_epochs=1,\n    per_gpu_train_batch_size=64,\n    save_steps=10_000,\n    save_total_limit=2,\n    prediction_loss_only=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=dataset,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained('model/krv_model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLinks\nFileLinks(r'model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}