{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom transformers import RobertaConfig, AdamW\nfrom transformers import RobertaForMaskedLM, get_cosine_schedule_with_warmup\nfrom transformers import RobertaTokenizerFast\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom joblib import Parallel, delayed\nimport pickle\nfrom torch import nn\nimport torch\nimport math\nfrom torch import cuda\nimport datetime\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-27T05:32:51.646498Z","iopub.execute_input":"2021-09-27T05:32:51.646794Z","iopub.status.idle":"2021-09-27T05:32:59.013925Z","shell.execute_reply.started":"2021-09-27T05:32:51.646725Z","shell.execute_reply":"2021-09-27T05:32:59.012969Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_train_test():\n    train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n    print(f'Our training set has {train.shape[0]} rows')\n    return train, test\n\ndef calc_wap1(df):\n    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n    return wap\n\ndef log_return(series):\n    return np.log(series).diff()\n\ndef book_preprocessor(delta, stock_id, is_train = True):\n    if is_train:\n        file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n    # Test\n    else:\n        file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n\n    df = pd.read_parquet(file_path_book)[['time_id', 'seconds_in_bucket', 'bid_price1', 'ask_price1', 'bid_size1', 'ask_size1']]\n    df['wap1'] = calc_wap1(df)\n    df['row_id'] = str(stock_id) + '-' + df['time_id'].astype(str)\n    df['i'] = ((df['wap1'] - wap1_min)/delta).astype(int)\n    return df.groupby(['row_id']).apply(convert_to_str)\n    \ndef convert_to_str(g):\n    start = 0\n    if len(g) > 590:\n        start = 10\n    s = ''.join(str(g.i.values[start:])).replace('\\n', '')\n    return s[1: len(s) - 1] + ' . '\n\ndef regression_calculate_rmse(y_pred, y_true):\n    delta = 0\n    for val1, val2 in zip(y_pred.cpu().numpy(), y_true.cpu().numpy()):\n        delta += np.square((val2 - val1) / val2)\n\n    return np.sqrt(delta/len(y_pred))\n\ndef rmspe(y_pred, y_true):\n    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n\ndef train(model, optimizer, epoch, lr_scheduler = None):\n    nb_tr_examples = 0\n    rmse = 0\n    \n    model.train()\n    for _,data in enumerate(training_loader, 0):\n        optimizer.zero_grad()\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.float)\n        \n        outputs = model(input_ids = ids, attention_mask = mask)\n\n        loss = loss_function(outputs.view(-1), targets.view(-1))\n        big_val, big_idx = torch.max(outputs.data, dim=1)\n        rmse += regression_calculate_rmse(big_val, targets)\n        \n        nb_tr_examples+=targets.size(0)\n\n        if nb_tr_examples % 10000 == 0:\n            epoch_rmse = math.sqrt(rmse/nb_tr_examples)\n            print(f\"{datetime.datetime.now().time()} : The number of trained samples ({nb_tr_examples}): {epoch_rmse}\")\n         \n        loss.backward()\n        # # When using GPU\n        optimizer.step()\n        if lr_scheduler != None:\n            lr_scheduler.step()\n\n    epoch_rmse = math.sqrt(rmse/nb_tr_examples)\n    print(f\"Training RMSE Epoch({epoch}): {epoch_rmse}\")\n\n    return \n\ndef valid(models, testing_loader):\n    rmse = 0; nb_tr_examples = 0;\n    if len(models) > 1:\n        print(f'valid: the number of good models is {len(models)}')\n    \n    with torch.no_grad():\n        for model in models:\n            model.eval()\n        for _, data in enumerate(testing_loader, 0):\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n            \n            outputs = model(input_ids = ids, attention_mask = mask)\n            for model in models[1:]:\n                outputs += model(input_ids = ids, attention_mask = mask)\n                \n            outputs /= len(models)\n            \n            loss = loss_function(outputs.view(-1), targets.view(-1))\n            big_val, big_idx = torch.max(outputs.data, dim=1)\n            rmse += regression_calculate_rmse(big_val, targets)\n\n            nb_tr_examples+=targets.size(0)\n            \n            if nb_tr_examples % 10000 == 0:\n                epoch_rmse = math.sqrt(rmse/nb_tr_examples)\n                print(f\"{datetime.datetime.now().time()} : The number of validated samples ({nb_tr_examples}): {epoch_rmse}\")\n            \n        epoch_rmse = math.sqrt(rmse/nb_tr_examples)\n        return epoch_rmse\n    \nclass Triage(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len, isSubmit = False):\n        self.len = len(dataframe)\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.isSubmit = isSubmit\n        \n    def __getitem__(self, index):\n        history = str(self.data.history[index])\n        inputs = self.tokenizer.encode_plus(\n            history,\n            None,\n            max_length=self.max_len,\n            padding = 'max_length',            \n            return_attention_mask=True,\n            truncation=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        if self.isSubmit:\n            row_id = self.data.row_id[index]\n            return {\n                'ids': torch.tensor(ids, dtype=torch.long),\n                'mask': torch.tensor(mask, dtype=torch.long),\n                'row_id'  : row_id\n            } \n        else:\n            return {\n                'ids': torch.tensor(ids, dtype=torch.long),\n                'mask': torch.tensor(mask, dtype=torch.long),\n                'targets': torch.tensor(self.data.target[index], dtype=torch.float)\n            } \n    \n    def __len__(self):\n        return self.len\n    \nclass LitModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        config = RobertaConfig.from_pretrained(model_name)\n        config.update({\"output_hidden_states\":True, \n                       \"hidden_dropout_prob\": 0.0,\n                       \"layer_norm_eps\": 1e-7})                       \n        \n        self.roberta = RobertaForMaskedLM.from_pretrained(model_name, config=config)  \n            \n        self.attention = torch.nn.Sequential(            \n            torch.nn.Linear(768, 512),            \n            torch.nn.Tanh(),                       \n            torch.nn.Linear(512, 1),\n            torch.nn.Softmax(dim=1)\n        )        \n\n        self.regressor = torch.nn.Sequential(                        \n            torch.nn.Linear(768, 1)                        \n        )\n        \n\n    def forward(self, input_ids, attention_mask):\n        roberta_output = self.roberta(input_ids=input_ids,\n                                      attention_mask=attention_mask)        \n\n        # There are a total of 13 layers of hidden states.\n        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n        # We take the hidden states from the last Roberta layer.\n        last_layer_hidden_states = roberta_output.hidden_states[-1]\n\n        # The number of cells is MAX_LEN.\n        # The size of the hidden state of each cell is 768 (for roberta-base).\n        # In order to condense hidden states of all cells to a context vector,\n        # we compute a weighted average of the hidden states of all cells.\n        # We compute the weight of each cell, using the attention neural network.\n        weights = self.attention(last_layer_hidden_states)\n                \n        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n        # Now we compute context_vector as the weighted average.\n        # context_vector.shape is BATCH_SIZE x 768\n        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n        # Now we reduce the context vector to the prediction score.\n        return self.regressor(context_vector)\n    \ndef create_optimizer(model):\n    named_parameters = list(model.named_parameters())    \n    \n    roberta_parameters = named_parameters[:197]    \n    attention_parameters = named_parameters[199:203]\n    regressor_parameters = named_parameters[203:]\n        \n    attention_group = [params for (name, params) in attention_parameters]\n    regressor_group = [params for (name, params) in regressor_parameters]\n\n    parameters = []\n    parameters.append({\"params\": attention_group})\n    parameters.append({\"params\": regressor_group})\n\n    for layer_num, (name, params) in enumerate(roberta_parameters):\n        weight_decay = 0.0 if \"bias\" in name else 0.01\n\n        lr = 2e-5\n\n        if layer_num >= 69:        \n            lr = 5e-5\n\n        if layer_num >= 133:\n            lr = 1e-4\n\n        parameters.append({\"params\": params,\n                           \"weight_decay\": weight_decay,\n                           \"lr\": lr})\n\n    return torch.optim.AdamW(parameters)\n\ndef save_model(model):\n    # Later need to upload to optiver-ml-final as new version\n    with open('model.pickle', 'wb') as f:\n        pickle.dump(model, f)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:39:34.996331Z","iopub.execute_input":"2021-09-27T10:39:34.996659Z","iopub.status.idle":"2021-09-27T10:39:35.038083Z","shell.execute_reply.started":"2021-09-27T10:39:34.996629Z","shell.execute_reply":"2021-09-27T10:39:35.037222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"delta = 0.0002\nwap1_min = 0.8830628395080566\nwap1_max = 1.1270768642425537\nvocab_size = int((wap1_max - wap1_min)/delta) + 2\nnum_secs_max = 600","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:33:14.77169Z","iopub.execute_input":"2021-09-27T05:33:14.772013Z","iopub.status.idle":"2021-09-27T05:33:14.776599Z","shell.execute_reply.started":"2021-09-27T05:33:14.771981Z","shell.execute_reply":"2021-09-27T05:33:14.77532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_run = False\nmodel_name = '../input/bert-for-optiver'\ntokenizer = RobertaTokenizerFast.from_pretrained('../input/krv-tokenizer')\n\nif first_run == True:\n    model_name = '../input/bert-for-optiver'\n    config = RobertaConfig.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:33:23.314567Z","iopub.execute_input":"2021-09-27T05:33:23.314881Z","iopub.status.idle":"2021-09-27T05:33:23.358949Z","shell.execute_reply.started":"2021-09-27T05:33:23.31485Z","shell.execute_reply":"2021-09-27T05:33:23.358179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/optiver-realized-volatility-prediction/'\n\ntrain, test = read_train_test()\ntrain_stock_ids = train['stock_id'].unique()\n\ndata = pd.DataFrame()\nfor stock_id in train_stock_ids:\n    df = pd.DataFrame(book_preprocessor(delta, stock_id), columns = ['history']).reset_index()\n    data = data.append(df)\n    \ndata = data.reset_index(drop = True)\ndata = data.merge(train[['target', 'row_id']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/prepared-optiver-data/optiver_new.csv', index_col = 0).sample(30000).reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:33:27.769781Z","iopub.execute_input":"2021-09-27T05:33:27.770103Z","iopub.status.idle":"2021-09-27T05:33:38.627021Z","shell.execute_reply.started":"2021-09-27T05:33:27.770072Z","shell.execute_reply":"2021-09-27T05:33:38.626193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mode = 'mAll'\n\nif mode != 'mTrain':\n    train_dataset, test_dataset = train_test_split(data, test_size = 0.2, random_state=200)\n    train_dataset=train_dataset.reset_index(drop=True)\n    test_dataset=test_dataset.reset_index(drop=True)\nelse:\n    train_dataset = data\n    train_dataset=train_dataset.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:33:42.602278Z","iopub.execute_input":"2021-09-27T05:33:42.602618Z","iopub.status.idle":"2021-09-27T05:33:42.620088Z","shell.execute_reply.started":"2021-09-27T05:33:42.602588Z","shell.execute_reply":"2021-09-27T05:33:42.618953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 600\nif mode == 'mTrain':\n    TRAIN_BATCH_SIZE = 1\nelse:\n    TRAIN_BATCH_SIZE = 16\nVALID_BATCH_SIZE = 2\n\ntraining_set = Triage(train_dataset, tokenizer, MAX_LEN)\ntrain_params = {'batch_size': TRAIN_BATCH_SIZE,\n                'drop_last': True,\n                'shuffle': True,\n                'num_workers': 2\n                }\ntraining_loader = DataLoader(training_set, **train_params)\n\nif mode != 'mTrain':\n    testing_set = Triage(test_dataset, tokenizer, MAX_LEN)\n    test_params = {'batch_size': VALID_BATCH_SIZE,\n                    'shuffle': True,\n                    'num_workers': 0\n                    }\n    testing_loader = DataLoader(testing_set, **test_params)\n\nloss_function = torch.nn.MSELoss()\n\nEPOCHS = 1\n\ndevice = 'cuda' if cuda.is_available() else 'cpu'\n\nif first_run == False:\n    with open('../input/optiver-ml-final/model_new.pickle', 'rb') as f:\n        model = pickle.load(f)\nelse:\n    model = LitModel()\nmodel.to(device)\n\noptimizer = create_optimizer(model)\nscheduler = get_cosine_schedule_with_warmup(\n    optimizer,\n    num_training_steps=EPOCHS * len(training_loader),\n    num_warmup_steps=50)    ","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:33:45.539748Z","iopub.execute_input":"2021-09-27T05:33:45.540204Z","iopub.status.idle":"2021-09-27T05:33:54.811013Z","shell.execute_reply.started":"2021-09-27T05:33:45.540159Z","shell.execute_reply":"2021-09-27T05:33:54.810073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = create_optimizer(model)\nscheduler = get_cosine_schedule_with_warmup(\n    optimizer,\n    num_training_steps=EPOCHS * len(training_loader),\n    num_warmup_steps=50)    ","metadata":{"execution":{"iopub.status.busy":"2021-09-27T10:39:57.529534Z","iopub.execute_input":"2021-09-27T10:39:57.529862Z","iopub.status.idle":"2021-09-27T10:39:57.560996Z","shell.execute_reply.started":"2021-09-27T10:39:57.529832Z","shell.execute_reply":"2021-09-27T10:39:57.560189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    train(model, optimizer, epoch, lr_scheduler = scheduler)\n    if mode != 'mTrain':\n        epoch_rmse = valid([model], testing_loader)\n        save_model(model)\n        \n        print(f\"Validation RMSE Epoch({epoch}): {epoch_rmse}\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-09-27T05:34:12.955058Z","iopub.execute_input":"2021-09-27T05:34:12.95541Z","iopub.status.idle":"2021-09-27T05:49:18.60121Z","shell.execute_reply.started":"2021-09-27T05:34:12.955376Z","shell.execute_reply":"2021-09-27T05:49:18.599704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import copy\ndef run_new_learn_strategy(model, nsamples = 30000, first_run = False):\n    run_continue = True\n    best_valid_rmse = 0.41\n    validat_counter = 0\n    model0 = copy.deepcopy(model)\n    \n    while run_continue:\n        data = pd.read_csv('../input/prepared-optiver-data/optiver_new.csv', index_col = 0).sample(nsamples).reset_index(drop = True)\n        train_dataset, test_dataset = train_test_split(data, test_size = 0.2)\n        train_dataset=train_dataset.reset_index(drop=True)\n        test_dataset=test_dataset.reset_index(drop=True)\n        \n        training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n        train_params = {'batch_size': TRAIN_BATCH_SIZE,\n                'drop_last': True,\n                'shuffle': True,\n                'num_workers': 2\n                }\n        training_loader = DataLoader(training_set, **train_params)\n\n        testing_set = Triage(test_dataset, tokenizer, MAX_LEN)\n        test_params = {'batch_size': VALID_BATCH_SIZE,\n                    'shuffle': True,\n                    'num_workers': 0\n                    }\n        testing_loader = DataLoader(testing_set, **test_params)\n        \n        optimizer = create_optimizer(model)\n        scheduler = get_cosine_schedule_with_warmup(optimizer, num_training_steps=EPOCHS * len(training_loader), num_warmup_steps=50)    \n\n        for epoch in range(EPOCHS):\n            train(model, optimizer, epoch, lr_scheduler = scheduler)\n            epoch_rmse = valid([model], testing_loader)\n            if epoch_rmse < best_valid_rmse:\n                best_valid_rmse = epoch_rmse\n                validat_counter = 0\n                model0 = copy.deepcopy(model)\n                #save_model(model0)\n            else:\n                model = copy.deepcopy(model0)\n                validat_counter += 1\n            print(f\"Validation RMSE Epoch({epoch}, counter = {validat_counter}): {epoch_rmse}\\n\")\n        \n        if validat_counter > 5:\n            run_continue = False","metadata":{"execution":{"iopub.status.busy":"2021-09-27T11:42:51.224726Z","iopub.execute_input":"2021-09-27T11:42:51.22506Z","iopub.status.idle":"2021-09-27T11:42:51.236826Z","shell.execute_reply.started":"2021-09-27T11:42:51.225026Z","shell.execute_reply":"2021-09-27T11:42:51.235873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_new_learn_strategy(model)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T11:42:54.765957Z","iopub.execute_input":"2021-09-27T11:42:54.766327Z","iopub.status.idle":"2021-09-27T13:14:24.183485Z","shell.execute_reply.started":"2021-09-27T11:42:54.766296Z","shell.execute_reply":"2021-09-27T13:14:24.18245Z"},"trusted":true},"execution_count":null,"outputs":[]}]}